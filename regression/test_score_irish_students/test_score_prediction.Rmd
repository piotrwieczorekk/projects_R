---
title: "DVRT (Drumcondra Verbal Reasoning Test Score) Prediction among irish students"
author: "Piotr Wieczorek"
date: "2023-11-12"
output: 
  html_document: 
    toc: yes
    toc_depth: 4
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE)
```

```{r}
rm(list=ls())
```

## Libraries


```{r}
library(tidyverse)
library(caret)
library(janitor)
library(naniar)
library(hrbrthemes)
library(missForest)
library(skimr)
library(gridExtra)
library(psych)
library(moments)
library(rcompanion)
library(randomForest)
```

## Loading the data

```{r}
df <- read.csv('irish_data.csv')
# link to the data set: https://www.openml.org/search?type=data&status=active&id=451
```


### Data description
* Sex: 1=male; 2=female.
* DVRT (Drumcondra Verbal Reasoning Test Score).
* Educational level attained
* Leaving Certificate. 1 if Leaving Certificate not taken; 2 if taken.
* Prestige score for father's occupation (calculated by Raftery and Hout, 1985).
* Type of school: 1=secondary; 2=vocational; 9=primary terminal leaver.

## Exploring and cleaning the data

```{r}
head(df)
```

### Changing character variables to factor variables

```{r}
df <- df %>%
  select(-c(1)) %>%
  mutate_if(is.character,as.factor)
```


```{r}
glimpse(df)
```

### Exploring factor variables' frequency

```{r}

for (colname in df %>% select_if(is.factor) %>% colnames()) {
  print(janitor::tabyl(df,colname))
  cat("\n")
}

```

##### There are 6 cases of Educational_level where we have missing data although it's not specified as NA

```{r}
df %>%
  filter(Educational_level == "")
```



### Handling NA values

#### Replacing blank values with NA

```{r}
df[df$Educational_level == "","Educational_level"] <- NA
```


```{r}
naniar::miss_var_summary(df)
```


#### Missing values plot


```{r}
naniar::gg_miss_var(df)
```

#### Random Forest imputation

```{r}
df_imputed <- missForest(as.data.frame(df))
```

```{r}
head(df_imputed$ximp)
```

```{r}
df_imputed$OOBerror
```


```{r}
df_clean <- df_imputed$ximp
```


```{r}
head(df_clean)
```

### Collapsing Educational_level factors

```{r}
summary(df_clean$Educational_level)
```


```{r}

df_clean <- df_clean %>%
  mutate(Educational_level = fct_collapse(Educational_level,
                                          "Junior_cycle" = c("Junior_cycle_incomplete-secondary_school",
                                                             "Junior_cycle_terminal_leaver-secondary_school",
                                                             "Junior_cycle_terminal_leaver-vocational_school",
                                                             "Junior_cycle_incomplete-vocational_school"),
                                          "3rd_level" = c("3rd_level_complete","3rd_level_incomplete"),
                                          "Senior_cycle" = c("Senior_cycle_incomplete-vocational_school",
                                                             "Senior_cycle_terminal_leaver-secondary_school",
                                                             "Senior_cycle_incomplete-secondary_school"
                                                             )))

```


```{r}
df_clean$Educational_level <- droplevels(df_clean$Educational_level)

levels(df_clean$Educational_level)
```

```{r}
summary(df_clean$Educational_level)
```



## Exploring DVRT (dependent variable)


### Descriptive statistics - DVRT groupped by Sex

```{r}
df_clean %>%
  group_by(Sex) %>%
  select(c("DVRT")) %>%
  skimr::skim()
```

### Plots

#### DVRT by sex


```{r,fig.width=12,fig.height=6}
grid.arrange(
  
  df_clean %>%
  ggplot(aes(x=Sex, y=DVRT,fill=Sex)) + 
  geom_boxplot()+ 
    labs(title="DVRT Boxplots by Sex") + 
   theme_ipsum_pub() + 
    theme(legend.position = "none"),
  
   df_clean %>%
    ggplot(aes(x=DVRT,fill=Sex)) + 
    geom_density(alpha=0.25)+ 
    labs(title="DVRT Density Plot by Sex") + 
   theme_ipsum_pub(),
  
  nrow=1,ncol=2


)

```


#### DVRT by Leaving_Certificate and Type_school


```{r,fig.width=14,fig.height=6}
grid.arrange(
  

 df_clean %>%
    ggplot(aes(x=Leaving_Certificate,y=DVRT,fill=Leaving_Certificate)) + 
    geom_boxplot()+ 
   labs(title="DVRT Boxplots by Leaving_Certificate") + 
   theme_ipsum_pub() + 
   theme(legend.position="none"),
  
  
  df_clean %>%
    ggplot(aes(x=Type_school,y=DVRT,fill=Type_school)) + 
    geom_boxplot() + 
   labs(title="DVRT Boxplots by Type_school") + 
   theme_ipsum_pub() + 
    theme(legend.position="none"),
 
 nrow=1,ncol=2)
```

#### DVRT by Educational_level

```{r,fig.width=12,fig.height=6}
df_clean %>%
    ggplot(aes(y=Educational_level,x=DVRT,fill=Educational_level)) + 
    geom_boxplot() + 
  labs(title="DVRT Boxplots by Educational_level") + 
  theme_ipsum_pub() + 
  theme(legend.position = "none") 
```


#### Relationship between Prestige_score and DVRT
```{r}
print(paste("Corr between Prestige_score and DVRT:",cor(x=df_clean$Prestige_score,y=df_clean$DVRT,method = 'spearman')))

df_clean %>%
  ggplot(aes(x=Prestige_score,y=DVRT))  +
  geom_point() + 
  geom_smooth(se=F)
```


## Modeling


```{r}
set.seed(123)
data_partition <- caret::createDataPartition(df_clean$DVRT,p=0.7,list=FALSE)

train_set <- df_clean[data_partition,]
test_set <- df_clean[-data_partition,]
```

### Linear model

```{r}
lm_mod <- lm(formula = DVRT ~. -Type_school -Leaving_Certificate, data=train_set)
print(summary(lm_mod))
```
#### Residual diagnostics

```{r}
par(mfrow=c(2,2))
plot(lm_mod)
```


#### Prediction

```{r}
test_set_prediction <- predict(lm_mod,test_set)
```

```{r}
length(test_set_prediction)
nrow(test_set)
```

```{r}
test_set$pred <- test_set_prediction
test_set$residual <- test_set$DVRT - test_set$pred
head(test_set)
```

#### MSR, MAE, MAPE
```{r}
paste("MSR:",mean(test_set$residual^2))
paste("MAE:",mean(abs(test_set$residual)))
paste("MAPE:",mean(abs(test_set$residual)/test_set$DVRT))
```


### Random Forest model
```{r}
set.seed(123)
rf_reg <- randomForest(DVRT ~. -Type_school -Leaving_Certificate,data=train_set,ntree=250,mtry=2,importance=TRUE)
```

```{r}
rf_reg
```

#### Relationship between the number of trees and Error

```{r}
plot(rf_reg)
```

#### Variable Importance plot


```{r}
varImpPlot(rf_reg,type=1)
```



```{r}
varImpPlot(rf_reg,type=2)
```
```{r}
length(predict(rf_reg,test_set))
```

#### Random Forest MSR

```{r}
paste("RF MSR:", mean((test_set$DVRT - predict(rf_reg,test_set))^2))
```

## Conclusion

Random Forest model is slightly better than the random forest model because its Mean of squared residuals metric is lower (150.53 for RF and 166 for linear model - both applied to the test set)




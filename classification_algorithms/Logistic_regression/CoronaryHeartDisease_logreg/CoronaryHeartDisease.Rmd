---
title: "Coronary Heart Disease Prediction"
author: "Piotr Wieczorek"
date: "2023-07-15"
output: 
  html_document: 
    theme: lumen
---

## Coronary Heart Disease Prediction (whether or not a patient is likely to develop a coronary heart disease in 10 years time)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE)
```

### Libraries


```{r}
rm(list=ls())
```

```{r}
library(caret)
library(tidyverse)
library(readr)
```




## Loading, exploring and cleaning the data
```{r}
df <- read_csv("framingham_heart_disease.csv")
```

```{r}
head(df)
```

```{r}
df <- df %>%
  select(-c("education"))
```

```{r}
sapply(df, function(x) sum(is.na(x)))
```
```{r}
df <- df %>%
  drop_na()
```

```{r}
head(df)
```

```{r}
df$TenYearCHD <- ifelse(df$TenYearCHD == 0, "No", "Yes")
```

```{r}
df <- df %>%
  mutate(TenYearCHD = as.factor(TenYearCHD))
```

```{r}
df <- df %>%
  mutate(gender = ifelse(male == 1, "male","female"))
```

```{r}
df <- df %>%
  mutate(gender = as.factor(gender)) %>%
  select(-c("male"))
```

```{r}
head(df)
```
```{r}
df <- df %>%
  mutate_at(c("currentSmoker","BPMeds","prevalentStroke","prevalentHyp","diabetes"),as.factor)
```


### Looking for potential near-zero-variance variables

```{r}
df %>%
  summary()
```

### BPMeds, prevalentStroke and diabetes are near-zero-variance variables.

```{r}
caret::nearZeroVar(df,names =TRUE)
```

### Train and test data set

```{r}
set.seed(786)
train_index <- createDataPartition(y= df$TenYearCHD,p=0.7, list= FALSE)
df_train <- df[train_index,]
df_test <- df[-train_index,]
nrow(df_train)
nrow(df_test)
nrow(df_train)/(nrow(df_train)+nrow(df_test))
```

### Checking possible Multicollinearity issues
```{r}
cor(df_train[,c("age","totChol","sysBP","diaBP","BMI","heartRate","glucose")])
```
### First model after excluding near-zero-variance variables and non-significant variables.

```{r}
mod <- glm(TenYearCHD ~. -prevalentStroke -BPMeds -diaBP -BMI -heartRate -currentSmoker -diabetes -prevalentHyp -glucose, data=df_train,family="binomial")
```


```{r}
summary(mod)
```

```{r}
first_mod_prediction <- predict(mod,df_test,type="response")
```

```{r}
first_mod_prediction_group <- ifelse(first_mod_prediction >= 0.5, "Yes","No")
```

### Although Accuracy is higher than No Information Rate, this model is purposeless as it predicts only ~5% of the "Yes" class of the TenYearCHD variable. The variable itself is unbalanced and that's presumably the reason why the model fails on predicting the "Yes" class. 

```{r}
confusionMatrix(as.factor(first_mod_prediction_group),reference = df_test$TenYearCHD,positive = "Yes")
```

### Solving the problem: Upsampling approach

### Upsampling is a technique commonly used in logistic regression modelling when the dependent variable is highly unbalanced, which often affects model's specificity

### Balancing the training set
```{r}
set.seed(123)

train_upsampling <- upSample(x=df_train[,-14],
                             y=df_train$TenYearCHD)
table(train_upsampling$Class)
```
```{r}
nearZeroVar(train_upsampling,names=TRUE)
```

```{r}
mod2 <- glm(Class ~. -BPMeds -prevalentStroke -diabetes -heartRate -currentSmoker,
            data = train_upsampling,family = "binomial")
```

```{r}
summary(mod2)
```

```{r}
second_mod_prediction <- predict(mod2,df_test,type="response")
second_mod_prediction_group <- ifelse(second_mod_prediction >= 0.5, "Yes","No")
second_mod_prediction_group <- as.factor(second_mod_prediction_group)
```

### This model has lower accuracy score than No Information Rate, but it's definitely more useful than the first one, because this time the model is much better at predicting "Yes" classes (at the cost of lower sensitivity).

```{r}
confusionMatrix(second_mod_prediction_group, df_test$TenYearCHD,positive = "Yes")
```












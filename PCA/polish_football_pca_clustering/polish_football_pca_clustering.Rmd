---
title: "The Highest Polish Football League (all time) PCA and Clustering"
author: "Piotr Wieczorek"
date: "2023-09-27"
output: 
  html_document: 
    toc: yes
    theme: journal
---

## Goal of the project

#### This Project aims to conduct PCA Analysis and K-means clustering on data regarding top football division of the 1927 - 2022/2023 seasons in Poland. Keep in mind that it is historical data and some teams that were taken into account do not exist today or represent regions that belong to other countries. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE, warning = FALSE)
```


## Libraries

```{r}
library(readr)
library(factoextra)
library(tidyverse)
library(psych)
library(kableExtra)
library(ggrepel)
```

## Reading and cleaning the data

```{r}
df <- read_csv("ekstraklasa.csv")
```

```{r}
df
```

```{r}
df$first_place_count <- sub("\\[.*$", "", df$first_place_count)
```


```{r}
df <- df[,c(2:13)]
```

```{r}
head(df)
```
```{r}
df <- df %>%
  mutate(name = as.factor(name),
         first_place_count = as.numeric(first_place_count))
```

```{r}
df
```

## Bartlett's Test of Sphericity

#### This test is uded to evaluate, whether there is a statistically significant divergence between the correlation matrix and the indentity matrix. Before we continue with PCA analysis, we have to make sure that there is some correlation in the original data.

#### Hypotheses:
* H0: These matrixes doesn't diverge
* Ha: These matrixes diverge

```{r}
bartlett.test(x = df %>% select_if(is.numeric), nrow(df))
```
#### P-value is extremely low, therefore we reject the H0.

## PCA Analysis

### Scaling the data, getting the eigenvalues and eigenvectors
```{r}
pca <- prcomp(x = df %>% select_if(is.numeric), scale.=TRUE)
```

```{r}
pca
```

### Variance

#### PCA1 and PCA2 capture ~97.26% of variance
```{r}
summary(pca)
```
### Scree plot

```{r}
fviz_eig(pca,addlabels = TRUE)
```

### Components Importance

```{r}
fviz_contrib(pca,choice="var")
```

```{r}
fviz_contrib(pca,choice="var",axes=2)
```

```{r}
cor(df$ranking,df$first_place_count)
```



### PCA Biplot
```{r}
fviz_pca_biplot(pca,label="var",repel = TRUE)
```

#### Interpretation - bear in mind that the lower the ranking, the better (for example 1 is the best)
1. ranking is negatively correlated with first_place_count (the more a particular team ended the season at the first place, the lower (better) the ranking)
2. ranking is also negatively correlated with total_wins, total_goals, total_points, season_count, total_draws, matches_played, total_goals_conceded, total_loses
2. total_goals, total_wins, first_place_count, total_goals_diff are positively correlated
3. total_loses, total_goals_conceded, total_draws, matches_played, season_count, total


## Clustering

### Assigning name variable as a rowname
```{r}
df_clustering <- df %>%
  remove_rownames() %>%
  column_to_rownames(var="name")
```


```{r}
head(df_clustering)
```
### Scaling the data

```{r}
df_clustering <- scale(df_clustering)
```

```{r}
head(df_clustering)
```
### Elbow plot

```{r}
fviz_nbclust(df_clustering,kmeans,method="wss")
```

### Fitting K-means algorithm on scaled data

```{r}
df_scaled_fit <- kmeans(df_clustering,3,nstart = 100)
```


### Cluster centers, Clustering vectors
```{r}
df_scaled_fit
```
### Adding data about clusters to df (the original dataframe without scaled data)
```{r}
df$clusters <- df_scaled_fit$cluster
```

```{r}
df %>%
  kable(align = "c") %>%
  kable_styling(position="center") %>%
  scroll_box(width = '100%', height = "500px")
```
### To the 1st cluster belong

```{r}
df %>%
  filter(clusters == 1) %>%
  select(c("name","clusters"))
```
### To the 2nd cluster belong

```{r}
df %>%
  filter(clusters == 2) %>%
  select(c("name","clusters"))
```

### To the 3rd cluster belong

```{r}
df %>%
  filter(clusters == 3) %>%
  select(c("name","clusters"))
```


```{r}
options(ggrepel.max.overlaps = Inf)
```

### Clustering Plot

```{r,fig.width=14,fig.height=10}
fviz_cluster(list(data=df_clustering,cluster= df_scaled_fit$cluster),repel = TRUE,ggtheme = theme_bw(),geom = c("text","point"))+
labs(title = "Cluster Plot") +
  theme(axis.text.x = element_text(hjust = 0.5, vjust = 0.5, size=15),
        axis.title.x =element_text(size=20),
        axis.text.y = element_text(hjust = 0.5, vjust = 0.5, size=15),
        axis.title.y =element_text(size=20),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black"),
        strip.text = element_text(size=25),
        title = element_text(size=25))
```
```{r}
pca
```

## Conclusions based on the Cluster Plot and Eigenvecteros

* Teams that are above 0.0 on the Dim2 axis exhibit: high first_place_count, high total_points, high total_wins, high total_goals, high total_goals_diff, low total_loses, low total_goals_conceded
* Teams that are below 0.0 on the Dim2 axis exhibit: low first_place_count, low total_goals_diff, high total_goals_conceded, high total_loses, high total_draws, high matches_played
* The more negative values on the Dim1 axis the lower (better) ranking, higher season_count, higher first_place_count, higher matches_played, higher_total_points, higher total_wins, higher total_draws, higher total_loses, higher total_goals, higher total_goals_conceded, higher total_goals_diff. In principle, the more history of played matches a team has, the lower PCA1 values it should exhibit
* The more positive (or less negative) values on the Dim1 axis the higher (worse) ranking, with all other features remaining relatively small





